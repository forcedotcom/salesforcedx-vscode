---
title: Einstein for Developers Glossary
lang: en
---

This glossary defines generative AI terms that appear throughout the Einstein documentation.

**generative pre-trained transformer (GPT):** A family of language models developed by OpenAI that are generally trained on a large corpus of text data so they can generate human-like text.

**Grounding:** The process through which domain-specific knowledge and customer information is injected into the prompt.
Human In the Loop (HITL): a model that requires human interaction.

**Intent:** A user’s goal for interacting with the AI-Assistant.

**Large Language Model (LLM):** A language model consisting of a neural network with many parameters trained on large quantities of text.

**Prompt:** A natural language description of the task to be accomplished. An input to the LLM.

**Prompt Management:** The suite of tools used to build, manage, package, and share prompts, including the prompt templates and the prompt template store.

**Prompt Template:** A string with placeholders/tags that can be replaced with custom values to generate a final prompt. The template includes the hyperparameters associated with that prompt, and model/vendor choice if not using default values.

**Prompt Chaining:** The method to select the right prompt engineering, which is a break-up of complex tasks into several intermediate steps, and then tie it back together in the hope that the AI generates a more concrete, customized, and thus better result. To get the best prompt, use the “Retry” option to regenerate code.

**Semantic Retrieval:** A scenario that allows a large language model to utilize all the knowledge that exists in a customer's CRM data. Each CRM user has access to a personalized generative AI.
